{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "url = \"C:\\\\Users\\\\DELL\\\\sentiment analysis\\\\synthetic_healthcare_reviews_with_text.csv\"   #url = r\"C:\\Users\\DELL\\sentiment analysis\\synthetic_healthcare_reviews_with_text.csv\"      #url = \"C:/Users/DELL/sentiment analysis/synthetic_healthcare_reviews_with_text.csv\"\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows where 'Review_Text' is null\n",
    "data_cleaned = df.dropna(subset=['Review_Text'])\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "print(data_cleaned)\n",
    "\n",
    "# Save the cleaned data to a new CSV file\n",
    "data_cleaned.to_csv('cleaned_data_sentiment_analysis.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "url_1 = \"C:\\\\Users\\\\DELL\\\\sentiment analysis\\\\cleaned_data_sentiment_analysis.csv\"   #url = r\"C:\\Users\\DELL\\sentiment analysis\\synthetic_healthcare_reviews_with_text.csv\"      #url = \"C:/Users/DELL/sentiment analysis/synthetic_healthcare_reviews_with_text.csv\"\n",
    "df = pd.read_csv(url_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r'\\W', ' ', str(text))\n",
    "    text = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', text)\n",
    "    text = re.sub(r'\\^[a-zA-Z]\\s+', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text, flags=re.I)\n",
    "    text = re.sub(r'^b\\s+', '', text)\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "# Apply the cleaning function to the review column, if it exists\n",
    "if 'Review_Text' in df.columns:\n",
    "    df['cleaned_review'] = df['Review_Text'].apply(clean_text)\n",
    "    print(df[['Review_Text', 'cleaned_review']].head())\n",
    "else:\n",
    "    print(\"The column 'review' does not exist in the dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Columns in the dataset:\", df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_rating_to_sentiment(rating):\n",
    "    if rating >= 4:\n",
    "        return 'Positive'\n",
    "    elif rating == 3:\n",
    "        return 'Neutral'\n",
    "    else:\n",
    "        return 'Negative'\n",
    "\n",
    "# Apply the function to the 'Rating' column to create a new 'Sentiment' column\n",
    "df['Sentiment'] = df['Rating'].apply(map_rating_to_sentiment)\n",
    "\n",
    "# Optionally, you can drop the original 'Rating' column if it's no longer needed\n",
    "# data.drop('Rating', axis=1, inplace=True)\n",
    "\n",
    "# Display the dataframe with the new 'Sentiment' column\n",
    "print(df[['cleaned_review','Rating', 'Sentiment']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the 'Review_Text' column\n",
    "df = df.drop(columns=['Rating'])\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(df)\n",
    "\n",
    "# Save the cleaned data to a new CSV file\n",
    "df.to_csv('cleaned_data_sentiment_analysis_fine.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Assuming your DataFrame is already loaded as 'df'\n",
    "# df = pd.read_csv('cleaned_data_sentiment_analysis_fine.csv')\n",
    "\n",
    "# Function to calculate polarity\n",
    "def get_polarity(text):\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "\n",
    "# Apply the function to the 'cleaned_review' column and create a new 'polarity' column\n",
    "df['polarity'] = df['cleaned_review'].apply(get_polarity)\n",
    "\n",
    "# Display the first few rows of the DataFrame with polarity\n",
    "print(df.head())\n",
    "# Save the cleaned data to a new CSV file\n",
    "df.to_csv('cleaned_data_sentiment_analysis_fine_polarity.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing Data\n",
    "url_2 = \"C:\\\\Users\\\\DELL\\\\sentiment analysis\\\\cleaned_data_sentiment_analysis_fine_polarity.csv\" \n",
    "df = pd.read_csv(url_2)\n",
    "import pandas as pd\n",
    "# Assume 'review_text' contains the text reviews and 'rating' contains the numerical ratings\n",
    "# Define conditions\n",
    "positive_condition = (df['polarity'] > 0) & (df['Sentiment'] == 'Positive')\n",
    "negative_condition = (df['polarity'] < 0) & (df['Sentiment'] == 'Negative')\n",
    "neutral_condition = (df['polarity'] >= -0.2) & (df['polarity'] <= 0.2) & (df['Sentiment'] == 'Neutral')\n",
    "\n",
    "# Filter the data based on the conditions\n",
    "filtered_df = df[positive_condition | negative_condition | neutral_condition]\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "print(filtered_df)\n",
    "print(filtered_df['Sentiment'].value_counts())\n",
    "\n",
    "# Save the cleaned data to a new CSV file\n",
    "filtered_df.to_csv('cleaned_data_sentiment_analysis_fine_polarity_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Convert text data into features (assuming you have preprocessed text data in 'cleaned_review' column)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(ngram_range=(1, 2), max_features=10000, min_df=2, max_df=0.8, stop_words='english')\n",
    "X_tfidf = tfidf.fit_transform(filtered_df['cleaned_review'])\n",
    "\n",
    "# Encode the 'Sentiment' column to numeric values\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(filtered_df['Sentiment'])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the classifier\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(filtered_df['Sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'Mean Squared Error: {mse:.2f}')\n",
    "print(f'R-squared: {r2:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "\n",
    "# Display the confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=label_encoder.classes_)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "# Calculate precision score with different averaging methods\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "print(f'Macro-Averaged Precision: {precision:.2f}')\n",
    "\n",
    "precision_micro = precision_score(y_test, y_pred, average='micro')\n",
    "print(f'Micro-Averaged Precision: {precision_micro:.2f}')\n",
    "\n",
    "precision_weighted = precision_score(y_test, y_pred, average='weighted')\n",
    "print(f'Weighted-Averaged Precision: {precision_weighted:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "# Calculate recall score with different averaging methods\n",
    "recall_macro = recall_score(y_test, y_pred, average='macro')\n",
    "print(f'Macro-Averaged Recall: {recall_macro:.2f}')\n",
    "\n",
    "recall_micro = recall_score(y_test, y_pred, average='micro')\n",
    "print(f'Micro-Averaged Recall: {recall_micro:.2f}')\n",
    "\n",
    "recall_weighted = recall_score(y_test, y_pred, average='weighted')\n",
    "print(f'Weighted-Averaged Recall: {recall_weighted:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = label_encoder.transform(filtered_df['Sentiment'])\n",
    "\n",
    "# Plot class distribution\n",
    "plt.figure(figsize=(8, 5))\n",
    "pd.Series(y).value_counts().plot(kind='bar', color='coral')\n",
    "plt.title('Class Distribution')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Number of Instances')\n",
    "plt.xticks(ticks=[0, 1, 2], labels=label_encoder.classes_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Separate the data into different classes\n",
    "df_positive = filtered_df[filtered_df['Sentiment'] == 'Positive']\n",
    "df_neutral = filtered_df[filtered_df['Sentiment'] == 'Neutral']\n",
    "df_negative = filtered_df[filtered_df['Sentiment'] == 'Negative']\n",
    "\n",
    "# Perform oversampling on the neutral class\n",
    "\n",
    "df_neutral_oversampled = resample(df_neutral, \n",
    "                                  replace=True,    # Sample with replacement\n",
    "                                  n_samples=len(df_negative),  # Match number of samples in positive class\n",
    "                                  random_state=42)  # For reproducibility\n",
    "df_positive_oversampled = resample(df_positive, \n",
    "                                  replace=True,    # Sample with replacement\n",
    "                                  n_samples=len(df_negative),  # Match number of samples in positive class\n",
    "                                  random_state=42)  # For reproducibility\n",
    "\n",
    "\n",
    "# Combine the oversampled neutral data with the original positive and negative data\n",
    "df_oversampled = pd.concat([df_positive_oversampled, df_neutral_oversampled, df_negative])\n",
    "\n",
    "# Shuffle the dataset to mix the samples\n",
    "df_oversampled = df_oversampled.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Check the class distribution after oversampling\n",
    "print(df_oversampled)\n",
    "\n",
    "# Convert text data into features (assuming you have preprocessed text data in 'cleaned_review' column)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(ngram_range=(1, 2), max_features=10000, min_df=2, max_df=0.8, stop_words='english')\n",
    "X_tfidf = tfidf.fit_transform(df_oversampled['cleaned_review'])\n",
    "\n",
    "# Encode the 'Sentiment' column to numeric values\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(df_oversampled['Sentiment'])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the classifier\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "\n",
    "new_reviews = [\"The doctor was incredibly attentive and took the time to explain everything.\", \"I had a great experience at the hospital; the staff were kind and professional.\", \"The surgery went smoothly, and the recovery process was well-managed.\", \"The nurses were compassionate and made me feel comfortable during my stay.\", \"I was seen quickly, and the treatment was effective. Highly recommend this clinic.\", \"The telemedicine service was very convenient, and the doctor was knowledgeable.\", \"I felt well cared for throughout my entire hospital stay. Excellent service!\", \"The facility was clean, and the staff were always ready to help.\", \"My appointment was on time, and the staff made sure I was comfortable.\", \"The healthcare team was professional, and I received top-notch care.\", \"The appointment was okay, but the wait time was a bit long.\", \"The service was decent, but I’ve had better experiences at other clinics.\", \"The treatment was adequate, but I felt it could have been more personalized.\", \"The staff were polite, but the environment felt a bit rushed.\", \"The care was satisfactory, but nothing stood out as exceptional.\", \"The hospital visit was fine, but the paperwork process was slow.\", \"The diagnosis was accurate, but the explanation could have been clearer.\", \"The facilities were clean, but the overall atmosphere was somewhat sterile.\", \"I received the treatment I needed, but the experience was just average.\", \"The consultation was helpful, but the follow-up could have been better.\", \"The wait time was unbearable, and the staff seemed disorganized.\", \"I was unhappy with the treatment plan; it felt rushed and impersonal.\", \"The hospital was understaffed, and I didn’t feel like I received adequate care.\", \"The nurse was rude and unprofessional during my visit.\", \"I had a terrible experience; the doctor didn’t listen to my concerns.\", \"The clinic was dirty, and the equipment looked outdated.\", \"I was misdiagnosed, which led to further complications.\", \"The receptionist was unhelpful and made the check-in process stressful.\", \"I felt neglected during my hospital stay; the staff were not attentive.\", \"The online consultation was frustrating, and I didn’t get the answers I needed.\", \"The doctor was knowledgeable, but the appointment felt rushed.\", \"The hospital staff were friendly, but the billing process was confusing.\", \"I appreciated the doctor’s expertise, but the wait time was too long.\", \"The care was good, but the hospital food was terrible.\", \"The staff were professional, but I didn’t feel a personal connection.\", \"The treatment worked, but the side effects weren’t explained to me.\", \"The nurse was helpful, but the room was not clean.\", \"The doctor was excellent, but the clinic’s location was inconvenient.\", \"The service was prompt, but I felt like just another number.\", \"The care was adequate, but the follow-up was lacking.\", \"The specialist was excellent, but getting an appointment was difficult.\", \"The telemedicine service was useful, but the connection quality was poor.\", \"The doctor was kind, but the overall experience was just okay.\", \"The hospital was modern, but the staff seemed overworked.\", \"The surgery was successful, but the aftercare instructions were confusing.\", \"The clinic was well-equipped, but the staff weren’t very friendly.\", \"The treatment was effective, but I didn’t feel well-informed about my options.\", \"The hospital stay was fine, but the noise level was too high.\", \"The doctor was caring, but the administrative staff were unhelpful.\", \"The healthcare service was good, but the waiting area was uncomfortable.\"\n",
    "]\n",
    "\n",
    "# Ensure the vectorizer is not refitted, only transform the new data\n",
    "new_tfidf_features = tfidf.transform(new_reviews)\n",
    "\n",
    "# Predict sentiment using the trained RandomForestClassifier model\n",
    "new_predictions = model.predict(new_tfidf_features)\n",
    "\n",
    "# Decode the numeric predictions back to original labels\n",
    "decoded_predictions = label_encoder.inverse_transform(new_predictions)\n",
    "\n",
    "print(decoded_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "\n",
    "#\n",
    "print(filtered_df['Sentiment'].value_counts())\n",
    "\n",
    "\n",
    "# Initialize the SVM classifier with probability=True\n",
    "model = SVC(probability=True, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Calculate Precision\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "print(f'Precision: {precision * 100:.2f}%')\n",
    "\n",
    "# Calculate Recall\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "print(f'Recall: {recall * 100:.2f}%')\n",
    "\n",
    "# Calculate F1 Score\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print(f'F1 Score: {f1 * 100:.2f}%')\n",
    "\n",
    "# Calculate ROC-AUC\n",
    "y_test_binarized = label_binarize(y_test, classes=[0, 1, 2])  # Assuming 3 classes: 0=Negative, 1=Neutral, 2=Positive\n",
    "y_pred_proba = model.predict_proba(X_test)\n",
    "roc_auc = roc_auc_score(y_test_binarized, y_pred_proba, average='weighted', multi_class='ovr')\n",
    "print(f'ROC-AUC: {roc_auc * 100:.2f}%')\n",
    "\n",
    "\n",
    "new_reviews = [\"The doctor was incredibly attentive and took the time to explain everything.\", \"I had a great experience at the hospital; the staff were kind and professional.\", \"The surgery went smoothly, and the recovery process was well-managed.\", \"The nurses were compassionate and made me feel comfortable during my stay.\", \"I was seen quickly, and the treatment was effective. Highly recommend this clinic.\", \"The telemedicine service was very convenient, and the doctor was knowledgeable.\", \"I felt well cared for throughout my entire hospital stay. Excellent service!\", \"The facility was clean, and the staff were always ready to help.\", \"My appointment was on time, and the staff made sure I was comfortable.\", \"The healthcare team was professional, and I received top-notch care.\", \"The appointment was okay, but the wait time was a bit long.\", \"The service was decent, but I’ve had better experiences at other clinics.\", \"The treatment was adequate, but I felt it could have been more personalized.\", \"The staff were polite, but the environment felt a bit rushed.\", \"The care was satisfactory, but nothing stood out as exceptional.\", \"The hospital visit was fine, but the paperwork process was slow.\", \"The diagnosis was accurate, but the explanation could have been clearer.\", \"The facilities were clean, but the overall atmosphere was somewhat sterile.\", \"I received the treatment I needed, but the experience was just average.\", \"The consultation was helpful, but the follow-up could have been better.\", \"The wait time was unbearable, and the staff seemed disorganized.\", \"I was unhappy with the treatment plan; it felt rushed and impersonal.\", \"The hospital was understaffed, and I didn’t feel like I received adequate care.\", \"The nurse was rude and unprofessional during my visit.\", \"I had a terrible experience; the doctor didn’t listen to my concerns.\", \"The clinic was dirty, and the equipment looked outdated.\", \"I was misdiagnosed, which led to further complications.\", \"The receptionist was unhelpful and made the check-in process stressful.\", \"I felt neglected during my hospital stay; the staff were not attentive.\", \"The online consultation was frustrating, and I didn’t get the answers I needed.\", \"The doctor was knowledgeable, but the appointment felt rushed.\", \"The hospital staff were friendly, but the billing process was confusing.\", \"I appreciated the doctor’s expertise, but the wait time was too long.\", \"The care was good, but the hospital food was terrible.\", \"The staff were professional, but I didn’t feel a personal connection.\", \"The treatment worked, but the side effects weren’t explained to me.\", \"The nurse was helpful, but the room was not clean.\", \"The doctor was excellent, but the clinic’s location was inconvenient.\", \"The service was prompt, but I felt like just another number.\", \"The care was adequate, but the follow-up was lacking.\", \"The specialist was excellent, but getting an appointment was difficult.\", \"The telemedicine service was useful, but the connection quality was poor.\", \"The doctor was kind, but the overall experience was just okay.\", \"The hospital was modern, but the staff seemed overworked.\", \"The surgery was successful, but the aftercare instructions were confusing.\", \"The clinic was well-equipped, but the staff weren’t very friendly.\", \"The treatment was effective, but I didn’t feel well-informed about my options.\", \"The hospital stay was fine, but the noise level was too high.\", \"The doctor was caring, but the administrative staff were unhelpful.\", \"The healthcare service was good, but the waiting area was uncomfortable.\"\n",
    "]\n",
    "\n",
    "# Ensure the vectorizer is not refitted, only transform the new data\n",
    "new_tfidf_features = tfidf.transform(new_reviews)\n",
    "\n",
    "# Predict sentiment using the trained model (best_model)\n",
    "new_predictions = best_model.predict(new_tfidf_features)\n",
    "\n",
    "# Decode the numeric predictions back to original labels\n",
    "decoded_predictions = label_encoder.inverse_transform(new_predictions)\n",
    "\n",
    "print(decoded_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Convert text data into features (assuming you have preprocessed text data in 'cleaned_review' column)\n",
    "tfidf = TfidfVectorizer(ngram_range=(1, 2), max_features=10000, min_df=2, max_df=0.8, stop_words='english')\n",
    "X_tfidf = tfidf.fit_transform(filtered_df['cleaned_review'])\n",
    "\n",
    "# Encode the 'Sentiment' column to numeric values\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(filtered_df['Sentiment'])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'kernel': ['linear', 'rbf', 'poly'],\n",
    "    'gamma': ['scale', 'auto'],\n",
    "    'degree': [2, 3, 4]  # Used only for 'poly' kernel\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV with SVM\n",
    "grid_search = GridSearchCV(SVC(probability=True, random_state=42), param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit the grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions using the best model\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy after hyperparameter tuning: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Calculate Precision\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "print(f'Precision: {precision * 100:.2f}%')\n",
    "\n",
    "# Calculate Recall\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "print(f'Recall: {recall * 100:.2f}%')\n",
    "\n",
    "# Calculate F1 Score\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print(f'F1 Score: {f1 * 100:.2f}%')\n",
    "\n",
    "# Calculate ROC-AUC\n",
    "y_test_binarized = label_binarize(y_test, classes=[0, 1, 2])  # Assuming 3 classes: 0=Negative, 1=Neutral, 2=Positive\n",
    "\n",
    "# Use best_model for prediction probabilities\n",
    "y_pred_proba = best_model.predict_proba(X_test)\n",
    "\n",
    "# Calculate ROC-AUC score\n",
    "roc_auc = roc_auc_score(y_test_binarized, y_pred_proba, average='weighted', multi_class='ovr')\n",
    "print(f'ROC-AUC: {roc_auc * 100:.2f}%')\n",
    "\n",
    "\n",
    "new_reviews = [\"The doctor was incredibly attentive and took the time to explain everything.\", \"I had a great experience at the hospital; the staff were kind and professional.\", \"The surgery went smoothly, and the recovery process was well-managed.\", \"The nurses were compassionate and made me feel comfortable during my stay.\", \"I was seen quickly, and the treatment was effective. Highly recommend this clinic.\", \"The telemedicine service was very convenient, and the doctor was knowledgeable.\", \"I felt well cared for throughout my entire hospital stay. Excellent service!\", \"The facility was clean, and the staff were always ready to help.\", \"My appointment was on time, and the staff made sure I was comfortable.\", \"The healthcare team was professional, and I received top-notch care.\", \"The appointment was okay, but the wait time was a bit long.\", \"The service was decent, but I’ve had better experiences at other clinics.\", \"The treatment was adequate, but I felt it could have been more personalized.\", \"The staff were polite, but the environment felt a bit rushed.\", \"The care was satisfactory, but nothing stood out as exceptional.\", \"The hospital visit was fine, but the paperwork process was slow.\", \"The diagnosis was accurate, but the explanation could have been clearer.\", \"The facilities were clean, but the overall atmosphere was somewhat sterile.\", \"I received the treatment I needed, but the experience was just average.\", \"The consultation was helpful, but the follow-up could have been better.\", \"The wait time was unbearable, and the staff seemed disorganized.\", \"I was unhappy with the treatment plan; it felt rushed and impersonal.\", \"The hospital was understaffed, and I didn’t feel like I received adequate care.\", \"The nurse was rude and unprofessional during my visit.\", \"I had a terrible experience; the doctor didn’t listen to my concerns.\", \"The clinic was dirty, and the equipment looked outdated.\", \"I was misdiagnosed, which led to further complications.\", \"The receptionist was unhelpful and made the check-in process stressful.\", \"I felt neglected during my hospital stay; the staff were not attentive.\", \"The online consultation was frustrating, and I didn’t get the answers I needed.\", \"The doctor was knowledgeable, but the appointment felt rushed.\", \"The hospital staff were friendly, but the billing process was confusing.\", \"I appreciated the doctor’s expertise, but the wait time was too long.\", \"The care was good, but the hospital food was terrible.\", \"The staff were professional, but I didn’t feel a personal connection.\", \"The treatment worked, but the side effects weren’t explained to me.\", \"The nurse was helpful, but the room was not clean.\", \"The doctor was excellent, but the clinic’s location was inconvenient.\", \"The service was prompt, but I felt like just another number.\", \"The care was adequate, but the follow-up was lacking.\", \"The specialist was excellent, but getting an appointment was difficult.\", \"The telemedicine service was useful, but the connection quality was poor.\", \"The doctor was kind, but the overall experience was just okay.\", \"The hospital was modern, but the staff seemed overworked.\", \"The surgery was successful, but the aftercare instructions were confusing.\", \"The clinic was well-equipped, but the staff weren’t very friendly.\", \"The treatment was effective, but I didn’t feel well-informed about my options.\", \"The hospital stay was fine, but the noise level was too high.\", \"The doctor was caring, but the administrative staff were unhelpful.\", \"The healthcare service was good, but the waiting area was uncomfortable.\"\n",
    "]\n",
    "\n",
    "# Ensure the vectorizer is not refitted, only transform the new data\n",
    "new_tfidf_features = tfidf.transform(new_reviews)\n",
    "\n",
    "# Predict sentiment using the trained model (best_model)\n",
    "new_predictions = best_model.predict(new_tfidf_features)\n",
    "\n",
    "# Decode the numeric predictions back to original labels\n",
    "decoded_predictions = label_encoder.inverse_transform(new_predictions)\n",
    "\n",
    "print(decoded_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Count the occurrences of each predicted sentiment\n",
    "sentiment_counts = np.unique(decoded_predictions, return_counts=True)\n",
    "\n",
    "# Create a bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=sentiment_counts[0], y=sentiment_counts[1], palette='viridis')\n",
    "plt.title('Distribution of Predicted Sentiments')\n",
    "plt.xlabel('Sentiment')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# Create a pie chart\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(sentiment_counts[1], labels=sentiment_counts[0], autopct='%1.1f%%', startangle=140, colors=sns.color_palette('viridis'))\n",
    "plt.title('Predicted Sentiment Distribution')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Convert text data into features (assuming you have preprocessed text data in 'cleaned_review' column)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "# Separate the data into different classes\n",
    "df_positive = filtered_df[filtered_df['Sentiment'] == 'Positive']\n",
    "df_neutral = filtered_df[filtered_df['Sentiment'] == 'Neutral']\n",
    "df_negative = filtered_df[filtered_df['Sentiment'] == 'Negative']\n",
    "\n",
    "# Perform oversampling on the neutral class\n",
    "\n",
    "df_neutral_oversampled = resample(df_neutral, \n",
    "                                  replace=True,    # Sample with replacement\n",
    "                                  n_samples=len(df_negative),  # Match number of samples in positive class\n",
    "                                  random_state=42)  # For reproducibility\n",
    "df_positive_oversampled = resample(df_positive, \n",
    "                                  replace=True,    # Sample with replacement\n",
    "                                  n_samples=len(df_negative),  # Match number of samples in positive class\n",
    "                                  random_state=42)  # For reproducibility\n",
    "\n",
    "\n",
    "# Combine the oversampled neutral data with the original positive and negative data\n",
    "df_oversampled = pd.concat([df_positive_oversampled, df_neutral_oversampled, df_negative])\n",
    "\n",
    "# Shuffle the dataset to mix the samples\n",
    "df_oversampled = df_oversampled.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Check the class distribution after oversampling\n",
    "print(df_oversampled)\n",
    "\n",
    "tfidf = TfidfVectorizer(ngram_range=(1, 2), max_features=10000, min_df=1, max_df=0.9, stop_words='english')\n",
    "X_tfidf = tfidf.fit_transform(df_oversampled['cleaned_review'])\n",
    "\n",
    "# Encode the 'Sentiment' column to numeric values\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(df_oversampled['Sentiment'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "\n",
    "# Initialize the Logistic Regression classifier\n",
    "logreg_model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Train the model\n",
    "logreg_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "logreg_predictions = logreg_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "logreg_accuracy = accuracy_score(y_test, logreg_predictions)\n",
    "print(f'Logistic Regression Accuracy: {logreg_accuracy * 100:.2f}%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# TF-IDF vectorization\n",
    "tfidf = TfidfVectorizer(ngram_range=(1, 2), max_features=10000, min_df=1, max_df=0.9, stop_words='english')\n",
    "X_tfidf = tfidf.fit_transform(df_oversampled['cleaned_review'])\n",
    "\n",
    "# Encode the 'Sentiment' column to numeric values\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(df_oversampled['Sentiment'])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "\n",
    "\n",
    "# 2. Train and evaluate Voting Classifier\n",
    "# Define the models for VotingClassifier\n",
    "model1 = LogisticRegression(max_iter=1000)\n",
    "model2 = RandomForestClassifier()\n",
    "model3 = SVC(probability=True)\n",
    "\n",
    "# Initialize the Voting Classifier\n",
    "voting_model = VotingClassifier(estimators=[\n",
    "    ('lr', model1), ('rf', model2), ('svc', model3)\n",
    "], voting='soft')\n",
    "\n",
    "# Train the Voting Classifier\n",
    "voting_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions with Voting Classifier\n",
    "voting_predictions = voting_model.predict(X_test)\n",
    "\n",
    "# Calculate Voting Classifier accuracy\n",
    "voting_accuracy = accuracy_score(y_test, voting_predictions)\n",
    "print(f'Voting Classifier Accuracy: {voting_accuracy * 100:.2f}%')\n",
    "\n",
    "# Optional: You can calculate other metrics like precision, recall, and F1 score for both models\n",
    "# Logistic Regression metrics\n",
    "logreg_precision = precision_score(y_test, logreg_predictions, average='weighted')\n",
    "logreg_recall = recall_score(y_test, logreg_predictions, average='weighted')\n",
    "logreg_f1 = f1_score(y_test, logreg_predictions, average='weighted')\n",
    "\n",
    "print(f'Logistic Regression Precision: {logreg_precision * 100:.2f}%')\n",
    "print(f'Logistic Regression Recall: {logreg_recall * 100:.2f}%')\n",
    "print(f'Logistic Regression F1 Score: {logreg_f1 * 100:.2f}%')\n",
    "\n",
    "# Voting Classifier metrics\n",
    "voting_precision = precision_score(y_test, voting_predictions, average='weighted')\n",
    "voting_recall = recall_score(y_test, voting_predictions, average='weighted')\n",
    "voting_f1 = f1_score(y_test, voting_predictions, average='weighted')\n",
    "\n",
    "print(f'Voting Classifier Precision: {voting_precision * 100:.2f}%')\n",
    "print(f'Voting Classifier Recall: {voting_recall * 100:.2f}%')\n",
    "print(f'Voting Classifier F1 Score: {voting_f1 * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Convert text data into features using TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(ngram_range=(1, 2), max_features=10000, min_df=2, max_df=0.8, stop_words='english')\n",
    "X_tfidf = tfidf.fit_transform(filtered_df['cleaned_review'])\n",
    "\n",
    "# Encode the 'Sentiment' column to numeric values\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(filtered_df['Sentiment'])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Naive Bayes classifier\n",
    "model = MultinomialNB()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "\n",
    "# New Reviews to predict their sentiments\n",
    "new_reviews = [\n",
    "    \"The doctor was incredibly attentive and took the time to explain everything.\",\n",
    "    \"I had a great experience at the hospital; the staff were kind and professional.\",\n",
    "    \"The surgery went smoothly, and the recovery process was well-managed.\",\n",
    "    \"The nurses were compassionate and made me feel comfortable during my stay.\",\n",
    "    \"I was seen quickly, and the treatment was effective. Highly recommend this clinic.\",\n",
    "    # Add more new reviews here...\n",
    "]\n",
    "\n",
    "# Ensure the vectorizer is not refitted, only transform the new data\n",
    "new_tfidf_features = tfidf.transform(new_reviews)\n",
    "\n",
    "# Predict sentiment using the trained MultinomialNB model\n",
    "new_predictions = model.predict(new_tfidf_features)\n",
    "\n",
    "# Decode the numeric predictions back to original labels\n",
    "decoded_predictions = label_encoder.inverse_transform(new_predictions)\n",
    "\n",
    "print(decoded_predictions)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
